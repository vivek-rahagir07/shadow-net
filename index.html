<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VisionAssist AI: Shadow Net & ASL Bridge</title>
    
    <!-- React & ReactDOM -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    
    <!-- Babel for JSX -->
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- TensorFlow.js and Models -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

    <!-- Icons -->
    <script src="https://unpkg.com/lucide@latest"></script>

    <style>
        body {
            background-color: #0f172a;
            color: #f8fafc;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            aspect-ratio: 4/3;
            overflow: hidden;
            border-radius: 1rem;
            background: #1e293b;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.5);
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror effect for better UX */
        }
        .scan-line {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: #22d3ee;
            box-shadow: 0 0 10px #22d3ee;
            animation: scan 2s linear infinite;
            z-index: 10;
            opacity: 0.7;
        }
        @keyframes scan {
            0% { top: 0%; }
            100% { top: 100%; }
        }
        .gesture-progress {
            transition: width 0.1s linear;
        }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef, useCallback } = React;

        // --- Utility Components ---

        const Button = ({ onClick, children, className = "", variant = "primary", iconName }) => {
            const btnRef = useRef(null);

            // Using Lucide with React via CDN requires manual triggering of icon replacement
            useEffect(() => {
                if (window.lucide && iconName && btnRef.current) {
                    window.lucide.createIcons({
                        root: btnRef.current,
                        nameAttr: 'data-lucide'
                    });
                }
            }); // Run on every render to ensure icon persists

            const baseStyle = "flex items-center justify-center gap-2 px-6 py-3 rounded-lg font-bold transition-all duration-200 transform hover:scale-105 active:scale-95";
            const variants = {
                primary: "bg-blue-600 hover:bg-blue-500 text-white shadow-lg shadow-blue-500/30",
                secondary: "bg-slate-700 hover:bg-slate-600 text-white border border-slate-600",
                danger: "bg-red-500 hover:bg-red-400 text-white",
                accent: "bg-cyan-500 hover:bg-cyan-400 text-slate-900 shadow-lg shadow-cyan-500/30",
                success: "bg-green-600 hover:bg-green-500 text-white shadow-lg shadow-green-500/30"
            };

            return (
                <button ref={btnRef} onClick={onClick} className={`${baseStyle} ${variants[variant]} ${className}`}>
                    {iconName && <i data-lucide={iconName} className="w-5 h-5"></i>}
                    {children}
                </button>
            );
        };

        const Loader = ({ text }) => (
            <div className="flex flex-col items-center justify-center h-full space-y-4">
                <div className="w-12 h-12 border-4 border-cyan-500 border-t-transparent rounded-full animate-spin"></div>
                <p className="text-cyan-400 animate-pulse font-mono">{text}</p>
            </div>
        );

        // --- Shadow Net Component (Object Detection) ---

        const ShadowNet = ({ onBack }) => {
            const videoRef = useRef(null);
            const canvasRef = useRef(null);
            const [model, setModel] = useState(null);
            const [loading, setLoading] = useState(true);
            const [lastSpoken, setLastSpoken] = useState("");
            const lastSpeakTime = useRef(0);

            // Speech Synthesis
            const speak = (text) => {
                const now = Date.now();
                // Throttle speech to avoid chaos (every 2.5 seconds max)
                if (now - lastSpeakTime.current < 2500) return;
                
                if (window.speechSynthesis) {
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.rate = 1.1;
                    utterance.pitch = 1;
                    window.speechSynthesis.speak(utterance);
                    setLastSpoken(text);
                    lastSpeakTime.current = now;
                }
            };

            // Setup Camera
            useEffect(() => {
                const setupCamera = async () => {
                    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                        try {
                            const stream = await navigator.mediaDevices.getUserMedia({
                                video: { facingMode: "environment" },
                                audio: false,
                            });
                            if (videoRef.current) {
                                videoRef.current.srcObject = stream;
                                return new Promise((resolve) => {
                                    videoRef.current.onloadedmetadata = () => {
                                        resolve(videoRef.current);
                                    };
                                });
                            }
                        } catch (e) {
                            alert("Camera access denied.");
                        }
                    }
                };

                const loadModel = async () => {
                    try {
                        await setupCamera();
                        const loadedModel = await cocoSsd.load();
                        setModel(loadedModel);
                        setLoading(false);
                        speak("Shadow Net activated. Scanning environment.");
                    } catch (err) {
                        console.error("Failed to load Shadow Net:", err);
                    }
                };

                loadModel();

                // Cleanup
                return () => {
                    window.speechSynthesis.cancel();
                    if (videoRef.current && videoRef.current.srcObject) {
                        videoRef.current.srcObject.getTracks().forEach(track => track.stop());
                    }
                };
            }, []);

            // Detection Loop
            useEffect(() => {
                if (!model || loading) return;

                let animationId;
                const detectFrame = async () => {
                    if (videoRef.current && videoRef.current.readyState === 4) {
                        const predictions = await model.detect(videoRef.current);
                        
                        // Draw
                        const ctx = canvasRef.current.getContext('2d');
                        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
                        ctx.font = '18px sans-serif';
                        ctx.textBaseline = 'top';

                        // Process predictions
                        let prominentObject = null;
                        let maxArea = 0;

                        predictions.forEach(prediction => {
                            const [x, y, width, height] = prediction.bbox;
                            const area = width * height;

                            // Draw bounding box
                            ctx.strokeStyle = '#22d3ee';
                            ctx.lineWidth = 4;
                            ctx.strokeRect(x, y, width, height);

                            // Draw label background
                            ctx.fillStyle = '#22d3ee';
                            const textWidth = ctx.measureText(prediction.class).width;
                            ctx.fillRect(x, y, textWidth + 10, 25);

                            // Draw label text
                            ctx.fillStyle = '#000000';
                            ctx.fillText(prediction.class, x + 5, y + 5);

                            // Determine most prominent object (closest/largest)
                            if (area > maxArea) {
                                maxArea = area;
                                prominentObject = prediction.class;
                            }
                        });

                        // Audio Feedback Logic
                        if (prominentObject) {
                             speak(`${prominentObject} detected`);
                        }
                    }
                    animationId = requestAnimationFrame(detectFrame);
                };

                detectFrame();

                return () => cancelAnimationFrame(animationId);
            }, [model, loading]);

            return (
                <div className="flex flex-col items-center w-full max-w-2xl mx-auto p-4 animate-fade-in">
                    <div className="flex justify-between w-full items-center mb-4">
                        <h2 className="text-2xl font-bold text-cyan-400 flex items-center gap-2">
                            <i data-lucide="eye" className="w-6 h-6"></i> Shadow Net
                        </h2>
                        <Button onClick={onBack} variant="secondary" className="px-3 py-1 text-sm">Exit</Button>
                    </div>

                    <div className="video-container">
                        {loading && <div className="absolute inset-0 z-20 bg-slate-900"><Loader text="Initializing Neural Network..." /></div>}
                        <div className="scan-line"></div>
                        <video ref={videoRef} autoPlay playsInline muted width="640" height="480" />
                        <canvas ref={canvasRef} width="640" height="480" />
                    </div>

                    <div className="mt-6 p-4 bg-slate-800 rounded-lg w-full border border-slate-700">
                        <p className="text-slate-400 text-sm uppercase tracking-wider mb-1">Status Log</p>
                        <p className="text-xl text-white font-mono min-h-[1.5em]">
                            {lastSpoken ? `> ${lastSpoken}` : "> Listening..."}
                        </p>
                    </div>
                </div>
            );
        };

        // --- ASL Bridge Component (Gesture Recognition) ---

        const AslBridge = ({ onBack }) => {
            const videoRef = useRef(null);
            const canvasRef = useRef(null);
            const [model, setModel] = useState(null);
            const [loading, setLoading] = useState(true);
            const [recognitionMode, setRecognitionMode] = useState('numbers'); // 'numbers' or 'letters'
            
            const [currentGesture, setCurrentGesture] = useState(null);
            const [sentence, setSentence] = useState([]);
            const [progress, setProgress] = useState(0); 
            
            const gestureStartTimeRef = useRef(0);
            const lastGestureRef = useRef(null);
            const animationFrameRef = useRef(null);

            // --- Speech Logic ---
            const speak = (text) => {
                if ('speechSynthesis' in window) {
                    window.speechSynthesis.cancel();
                    const utterance = new SpeechSynthesisUtterance(text);
                    window.speechSynthesis.speak(utterance);
                }
            };

            const speakSentence = () => {
                const text = sentence.join(" ");
                if (!text) return;
                speak(text);
            };

            // --- Geometric Hand Analysis ---
            const analyzeHand = (landmarks) => {
                // Landmarks: 0=wrist, 1-4=thumb, 5-8=index, 9-12=middle, 13-16=ring, 17-20=pinky
                
                // 1. Calculate Finger Extensions
                const isExtended = (tipIdx, pipIdx) => landmarks[tipIdx][1] < landmarks[pipIdx][1];
                const fingers = [
                    isExtended(8, 6),   // Index
                    isExtended(12, 10), // Middle
                    isExtended(16, 14), // Ring
                    isExtended(20, 18)  // Pinky
                ];
                
                // Thumb is tricky (horizontal movement vs vertical)
                // If thumb tip is 'higher' (smaller Y) than MCP joint OR 'farther' from palm center than MCP
                const thumbTip = landmarks[4];
                const thumbIp = landmarks[3];
                const thumbMcp = landmarks[2];
                const wrist = landmarks[0];
                
                // Simple Thumb Extension: Tip is above IP joint (screen coordinates, y is down)
                // OR Tip is significantly to the side
                const thumbUp = thumbTip[1] < thumbIp[1];
                const thumbOut = Math.abs(thumbTip[0] - thumbMcp[0]) > 30;
                
                // 2. Calculate Pinches (Tips close to thumb tip)
                const pinchThreshold = 40;
                const getDistance = (p1, p2) => Math.sqrt(Math.pow(p1[0]-p2[0], 2) + Math.pow(p1[1]-p2[1], 2));
                
                const pinches = [
                    getDistance(thumbTip, landmarks[8]) < pinchThreshold,  // Index
                    getDistance(thumbTip, landmarks[12]) < pinchThreshold, // Middle
                    getDistance(thumbTip, landmarks[16]) < pinchThreshold, // Ring
                    getDistance(thumbTip, landmarks[20]) < pinchThreshold  // Pinky
                ];

                // 3. Other Geometries
                const indexMiddleDistance = getDistance(landmarks[8], landmarks[12]);
                const crossed = (landmarks[8][0] > landmarks[12][0] && landmarks[6][0] < landmarks[10][0]) || 
                               (landmarks[8][0] < landmarks[12][0] && landmarks[6][0] > landmarks[10][0]);

                return { fingers, thumbUp, thumbOut, pinches, indexMiddleDistance, crossed };
            };

            // --- Classification Logic ---
            const recognize = (data, mode) => {
                const { fingers, thumbUp, thumbOut, pinches, indexMiddleDistance, crossed } = data;
                const [index, middle, ring, pinky] = fingers;
                const count = fingers.filter(f => f).length;

                // --- Number Mode ---
                if (mode === 'numbers') {
                    if (count === 5 && thumbOut) return "5";
                    if (count === 4 && !thumbUp) return "4"; // Thumb tucked
                    if (count === 4 && thumbOut) return "5"; // Loose 5
                    
                    if (index && middle && ring && !pinky && thumbOut) return "6"; // ASL W style is sometimes 6? No, ASL 6 is pinky touch
                    
                    // ASL Specific Numbers (Touching)
                    if (pinches[3] && index && middle && ring) return "6"; // Pinky touch thumb
                    if (pinches[2] && index && middle && pinky) return "7"; // Ring touch thumb
                    if (pinches[1] && index && ring && pinky) return "8";   // Mid touch thumb
                    if (pinches[0] && middle && ring && pinky) return "9";  // Index touch thumb (F shape)
                    
                    if (index && middle && !ring && !pinky) return "2";
                    if (index && !middle && !ring && !pinky) return "1";
                    
                    if (!index && !middle && !ring && !pinky) {
                         // Fist variants
                         if (thumbUp) return "10"; // Thumbs up is 10 in this simplified model (ASL 10 is shaking thumb)
                         return "0"; // Fist
                    }
                    
                    // ASL 3: Thumb, Index, Mid extended
                    if (thumbOut && index && middle && !ring && !pinky) return "3";
                    
                    // Standard counting 3 (Index, Mid, Ring)
                    if (!thumbOut && index && middle && ring && !pinky) return "3";
                }

                // --- Letter Mode ---
                if (mode === 'letters') {
                    // Fist Based
                    if (!index && !middle && !ring && !pinky) {
                        if (thumbUp) return "A"; // Thumb on side/up
                        // S is thumb over fingers (hard to distinguish from A without depth)
                        // T is thumb between index/mid (hard)
                        // E is curled fingers (fingertips visible)
                        return "S"; // Default fist to S or A
                    }

                    // Single Finger
                    if (index && !middle && !ring && !pinky) {
                        if (thumbOut) return "L";
                        // D? Index up, thumb touches middle.
                        if (pinches[1]) return "D";
                        return "1"; // Fallback/Z (Z needs motion)
                    }
                    
                    // Pinky Only
                    if (!index && !middle && !ring && pinky) {
                         if (thumbOut) return "Y";
                         return "I";
                    }

                    // Two Fingers
                    if (index && middle && !ring && !pinky) {
                        if (crossed) return "R";
                        if (indexMiddleDistance > 45) return "V";
                        return "U"; // Fingers together
                    }

                    // K (Index, Middle, Thumb between) - hard, looks like V
                    // P (Index down) - hard in this orientation check

                    // Three Fingers
                    if (index && middle && ring && !pinky) {
                         if (thumbOut) return "3"; // or W in some contexts?
                         return "W";
                    }
                    
                    // F (Index touches thumb, others splayed)
                    if (pinches[0] && middle && ring && pinky) return "F";

                    // Open Hand
                    if (index && middle && ring && pinky) {
                         if (thumbOut) return "C"; // If hand is curved (hard to tell in 2D) -> C usually horizontal
                         return "B"; // Flat hand
                    }
                    
                    // "I Love You" sign
                    if (index && pinky && !middle && !ring && thumbOut) return "ðŸ¤Ÿ";
                }

                return null;
            };

            // --- Main Loop ---
            useEffect(() => {
                const setupCamera = async () => {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { width: 640, height: 480 },
                        audio: false,
                    });
                    if (videoRef.current) {
                        videoRef.current.srcObject = stream;
                        return new Promise((resolve) => videoRef.current.onloadedmetadata = () => resolve(videoRef.current));
                    }
                };

                const init = async () => {
                    await setupCamera();
                    const loadedModel = await handpose.load();
                    setModel(loadedModel);
                    setLoading(false);
                };

                init();

                return () => {
                    if (videoRef.current && videoRef.current.srcObject) {
                        videoRef.current.srcObject.getTracks().forEach(track => track.stop());
                    }
                    cancelAnimationFrame(animationFrameRef.current);
                };
            }, []);

            useEffect(() => {
                if (!model || loading) return;

                const loop = async () => {
                    if (videoRef.current && videoRef.current.readyState === 4) {
                        const predictions = await model.estimateHands(videoRef.current);
                        const ctx = canvasRef.current.getContext('2d');
                        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);

                        if (predictions.length > 0) {
                            const landmarks = predictions[0].landmarks;

                            // Draw Skeleton
                            landmarks.forEach(point => {
                                ctx.beginPath();
                                ctx.arc(point[0], point[1], 5, 0, 2 * Math.PI);
                                ctx.fillStyle = "#fbbf24";
                                ctx.fill();
                            });

                            // Analyze and Recognize
                            const handData = analyzeHand(landmarks);
                            const gestureResult = recognize(handData, recognitionMode);
                            
                            // Hold-to-confirm Logic
                            if (gestureResult) {
                                if (gestureResult === lastGestureRef.current) {
                                    const duration = Date.now() - gestureStartTimeRef.current;
                                    const percentage = Math.min((duration / 1000) * 100, 100);
                                    setProgress(percentage);

                                    if (duration > 1000) { 
                                        setSentence(prev => [...prev, gestureResult]);
                                        speak(gestureResult.length === 1 ? gestureResult.toLowerCase() : gestureResult);
                                        gestureStartTimeRef.current = Date.now(); 
                                        setProgress(0);
                                    }
                                } else {
                                    lastGestureRef.current = gestureResult;
                                    gestureStartTimeRef.current = Date.now();
                                    setProgress(0);
                                }
                                setCurrentGesture(gestureResult);
                            } else {
                                setCurrentGesture(null);
                                setProgress(0);
                                lastGestureRef.current = null;
                            }
                        }
                    }
                    animationFrameRef.current = requestAnimationFrame(loop);
                };

                loop();
            }, [model, loading, recognitionMode]);

            return (
                 <div className="flex flex-col items-center w-full max-w-2xl mx-auto p-4 animate-fade-in pb-24">
                    <div className="flex justify-between w-full items-center mb-4">
                        <h2 className="text-2xl font-bold text-amber-400 flex items-center gap-2">
                            <i data-lucide="hand" className="w-6 h-6"></i> ASL Bridge
                        </h2>
                        <Button onClick={onBack} variant="secondary" className="px-3 py-1 text-sm">Exit</Button>
                    </div>

                    {/* Mode Toggle */}
                    <div className="flex bg-slate-800 p-1 rounded-lg mb-4 border border-slate-700">
                        <button 
                            onClick={() => setRecognitionMode('numbers')}
                            className={`px-4 py-2 rounded-md text-sm font-bold transition-all ${recognitionMode === 'numbers' ? 'bg-amber-500 text-slate-900 shadow-lg' : 'text-slate-400 hover:text-white'}`}
                        >
                            123 Numbers
                        </button>
                        <button 
                            onClick={() => setRecognitionMode('letters')}
                            className={`px-4 py-2 rounded-md text-sm font-bold transition-all ${recognitionMode === 'letters' ? 'bg-amber-500 text-slate-900 shadow-lg' : 'text-slate-400 hover:text-white'}`}
                        >
                            ABC Letters
                        </button>
                    </div>

                    <div className="video-container border-2 border-amber-500/30">
                        {loading && <div className="absolute inset-0 z-20 bg-slate-900"><Loader text="Loading Hand Pose Model..." /></div>}
                        <video ref={videoRef} autoPlay playsInline muted width="640" height="480" />
                        <canvas ref={canvasRef} width="640" height="480" />
                        
                        {/* Overlay */}
                        {currentGesture && (
                            <div className="absolute top-4 right-4 bg-black/60 backdrop-blur text-white px-4 py-2 rounded-lg border border-amber-500/50 flex flex-col items-center min-w-[80px]">
                                <span className="text-4xl font-bold text-amber-400">{currentGesture}</span>
                                {/* Progress Bar */}
                                <div className="w-full h-1 bg-gray-600 mt-2 rounded-full overflow-hidden">
                                    <div className="h-full bg-amber-400 gesture-progress" style={{width: `${progress}%`}}></div>
                                </div>
                            </div>
                        )}
                    </div>

                    {/* Sentence Builder */}
                    <div className="w-full mt-6 bg-slate-800 rounded-xl p-4 border border-slate-700 shadow-xl">
                        <div className="flex justify-between items-center mb-2">
                            <label className="text-xs font-bold text-slate-400 uppercase tracking-widest">Current Message</label>
                            <span className="text-xs text-slate-500">Hold gesture for 1s to add</span>
                        </div>
                        
                        <div className="min-h-[60px] bg-slate-900 rounded-lg p-3 mb-4 flex flex-wrap gap-2 items-center">
                            {sentence.length === 0 && <span className="text-slate-600 italic">Gestures will appear here...</span>}
                            {sentence.map((word, idx) => (
                                <span key={idx} className="bg-amber-900/40 text-amber-100 px-3 py-1 rounded-full border border-amber-500/30 text-lg font-mono">
                                    {word}
                                </span>
                            ))}
                        </div>

                        <div className="grid grid-cols-2 gap-3">
                            <Button onClick={speakSentence} variant="success" iconName="volume-2">
                                Speak
                            </Button>
                            <Button onClick={() => setSentence([])} variant="danger" iconName="trash-2">
                                Clear
                            </Button>
                        </div>
                    </div>
                </div>
            );
        };

        // --- Main App Component ---

        const App = () => {
            const [mode, setMode] = useState('home'); 

            // Initialize Lucide icons
            useEffect(() => {
                if(window.lucide) {
                    window.lucide.createIcons();
                }
            }, [mode]);

            if (mode === 'shadow') return <ShadowNet onBack={() => setMode('home')} />;
            if (mode === 'asl') return <AslBridge onBack={() => setMode('home')} />;

            return (
                <div className="min-h-screen flex flex-col items-center justify-center p-6 bg-gradient-to-b from-slate-900 to-slate-800">
                    <header className="mb-12 text-center">
                        <h1 className="text-4xl md:text-6xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-cyan-400 to-blue-500 mb-4">
                            VisionAssist AI
                        </h1>
                        <p className="text-slate-400 max-w-md mx-auto">
                            Advanced accessibility tools powered by browser-based neural networks.
                        </p>
                    </header>

                    <div className="grid md:grid-cols-2 gap-8 w-full max-w-4xl">
                        {/* Shadow Net Card */}
                        <div className="group relative bg-slate-800 p-8 rounded-2xl border border-slate-700 hover:border-cyan-500 transition-all duration-300 hover:shadow-2xl hover:shadow-cyan-500/20">
                            <div className="absolute inset-0 bg-cyan-500/5 rounded-2xl opacity-0 group-hover:opacity-100 transition-opacity"></div>
                            <div className="relative z-10 flex flex-col items-center text-center">
                                <div className="w-16 h-16 bg-cyan-900/50 rounded-full flex items-center justify-center mb-6 text-cyan-400">
                                    <i data-lucide="eye" className="w-8 h-8"></i>
                                </div>
                                <h2 className="text-2xl font-bold text-white mb-2">Shadow Net</h2>
                                <p className="text-slate-400 mb-6 text-sm">
                                    Environmental scanner for the visually impaired. Detects objects and provides real-time audio guidance.
                                </p>
                                <Button onClick={() => setMode('shadow')} variant="accent">
                                    Launch Scanner
                                </Button>
                            </div>
                        </div>

                        {/* ASL Bridge Card */}
                        <div className="group relative bg-slate-800 p-8 rounded-2xl border border-slate-700 hover:border-amber-500 transition-all duration-300 hover:shadow-2xl hover:shadow-amber-500/20">
                            <div className="absolute inset-0 bg-amber-500/5 rounded-2xl opacity-0 group-hover:opacity-100 transition-opacity"></div>
                            <div className="relative z-10 flex flex-col items-center text-center">
                                <div className="w-16 h-16 bg-amber-900/50 rounded-full flex items-center justify-center mb-6 text-amber-400">
                                    <i data-lucide="hand" className="w-8 h-8"></i>
                                </div>
                                <h2 className="text-2xl font-bold text-white mb-2">ASL Bridge</h2>
                                <p className="text-slate-400 mb-6 text-sm">
                                    Communication tool. Supports Alphabets (A-Z) and Numbers (0-10) with speech synthesis.
                                </p>
                                <Button onClick={() => setMode('asl')} variant="primary" className="bg-amber-600 hover:bg-amber-500 shadow-amber-500/30">
                                    Start Translator
                                </Button>
                            </div>
                        </div>
                    </div>

                    <footer className="mt-16 text-slate-600 text-sm">
                        &copy; 2024 VisionAssist â€¢ Powered by TensorFlow.js
                    </footer>
                </div>
            );
        };

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>